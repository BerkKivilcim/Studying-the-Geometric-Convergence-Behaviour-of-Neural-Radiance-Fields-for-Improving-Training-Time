#compdef ns-train

# AUTOMATICALLY GENERATED by `shtab`


_shtab_tyro_ns_train_commands() {
  local _commands=(
    "depth-nerfacto:Nerfacto with depth supervision."
    "dnerf:Dynamic-NeRF model. (slow)"
    "generfacto:Generative Text to NeRF model"
    "in2n:\[External\] Instruct-NeRF2NeRF. Full model, used in paper"
    "in2n-small:\[External\] Instruct-NeRF2NeRF. Half precision model"
    "in2n-tiny:\[External\] Instruct-NeRF2NeRF. Half prevision with no LPIPS"
    "instant-ngp:Implementation of Instant-NGP. Recommended real-time model for unbounded scenes."
    "instant-ngp-bounded:Implementation of Instant-NGP. Recommended for bounded real and synthetic scenes"
    "kplanes:\[External\] K-Planes model tuned to static blender scenes"
    "kplanes-dynamic:\[External\] K-Planes model tuned to dynamic DNeRF scenes"
    "lerf:\[External\] LERF with OpenCLIP ViT-B\/16, used in paper"
    "lerf-big:\[External\] LERF with OpenCLIP ViT-L\/14"
    "lerf-lite:\[External\] LERF with smaller network and less LERF samples"
    "mipnerf:High quality model for bounded scenes. (slow)"
    "nerfacto:Recommended real-time model tuned for real captures. This model will be continually updated."
    "nerfacto-big:"
    "nerfacto-huge:"
    "nerfplayer-nerfacto:\[External\] NeRFPlayer with nerfacto backbone"
    "nerfplayer-ngp:\[External\] NeRFPlayer with instang-ngp-bounded backbone"
    "neus:Implementation of NeuS. (slow)"
    "neus-facto:Implementation of NeuS-Facto. (slow)"
    "phototourism:Uses the Phototourism data."
    "reconstruction:Plugin for studying the reconstruction behaviour of NeRFs."
    "semantic-nerfw:Predicts semantic segmentations and filters out transient objects."
    "tensorf:tensorf"
    "tetra-nerf:\[External\] Tetra-NeRF. Different sampler - faster and better"
    "tetra-nerf-original:\[External\] Tetra-NeRF. Official implementation from the paper"
    "vanilla-nerf:Original NeRF model. (slow)"
    "volinga:\[External\] Real-time rendering model from Volinga. Directly exportable to NVOL format at https\:\/\/volinga.ai\/"
  )
  _describe 'ns-train commands' _commands
}

_shtab_tyro_ns_train_depth_nerfacto_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train depth-nerfacto commands' _commands
}

_shtab_tyro_ns_train_dnerf_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train dnerf commands' _commands
}

_shtab_tyro_ns_train_generfacto_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train generfacto commands' _commands
}

_shtab_tyro_ns_train_in2n_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train in2n commands' _commands
}

_shtab_tyro_ns_train_in2n_small_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train in2n-small commands' _commands
}

_shtab_tyro_ns_train_in2n_tiny_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train in2n-tiny commands' _commands
}

_shtab_tyro_ns_train_instant_ngp_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train instant-ngp commands' _commands
}

_shtab_tyro_ns_train_instant_ngp_bounded_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train instant-ngp-bounded commands' _commands
}

_shtab_tyro_ns_train_kplanes_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train kplanes commands' _commands
}

_shtab_tyro_ns_train_kplanes_dynamic_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train kplanes-dynamic commands' _commands
}

_shtab_tyro_ns_train_lerf_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train lerf commands' _commands
}

_shtab_tyro_ns_train_lerf_big_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train lerf-big commands' _commands
}

_shtab_tyro_ns_train_lerf_lite_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train lerf-lite commands' _commands
}

_shtab_tyro_ns_train_mipnerf_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train mipnerf commands' _commands
}

_shtab_tyro_ns_train_nerfacto_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train nerfacto commands' _commands
}

_shtab_tyro_ns_train_nerfacto_big_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train nerfacto-big commands' _commands
}

_shtab_tyro_ns_train_nerfacto_huge_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train nerfacto-huge commands' _commands
}

_shtab_tyro_ns_train_nerfplayer_nerfacto_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train nerfplayer-nerfacto commands' _commands
}

_shtab_tyro_ns_train_nerfplayer_ngp_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train nerfplayer-ngp commands' _commands
}

_shtab_tyro_ns_train_neus_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train neus commands' _commands
}

_shtab_tyro_ns_train_neus_facto_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train neus-facto commands' _commands
}

_shtab_tyro_ns_train_phototourism_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train phototourism commands' _commands
}

_shtab_tyro_ns_train_reconstruction_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train reconstruction commands' _commands
}

_shtab_tyro_ns_train_semantic_nerfw_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train semantic-nerfw commands' _commands
}

_shtab_tyro_ns_train_tensorf_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train tensorf commands' _commands
}

_shtab_tyro_ns_train_tetra_nerf_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train tetra-nerf commands' _commands
}

_shtab_tyro_ns_train_tetra_nerf_original_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train tetra-nerf-original commands' _commands
}

_shtab_tyro_ns_train_vanilla_nerf_commands() {
  local _commands=(
    "arkit-data:"
    "blender-data:"
    "colmap:"
    "dnerf-data:"
    "dycheck-data:"
    "instant-ngp-data:"
    "minimal-parser:"
    "nerfosr-data:"
    "nerfstudio-data:"
    "nuscenes-data:"
    "phototourism-data:"
    "scannet-data:"
    "sdfstudio-data:"
    "sitcoms3d-data:"
  )
  _describe 'ns-train vanilla-nerf commands' _commands
}

_shtab_tyro_ns_train_volinga_commands() {
  local _commands=(
    "pipeline.datamanager.camera-optimizer\:None:"
    "pipeline.datamanager.camera-optimizer\:camera-optimizer-config:Configuration of optimization for camera poses."
  )
  _describe 'ns-train volinga commands' _commands
}

_shtab_tyro_ns_train_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_depth_nerfacto_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: depth-nerfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.datamanager.pixel-sampler.radius[max distance between pairs of pixels. (default\: 2)]:pipeline.datamanager.pixel-sampler.radius:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(last_sample black white random)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.base-res[Resolution of the base grid for the hashgrid. (default\: 16)]:pipeline.model.base-res:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.features-per-level[How many hashgrid features per level (default\: 2)]:pipeline.model.features-per-level:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(uniform piecewise)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.use-gradient-scaling[Use gradient scaler where the gradients are lower for points closer to the camera. (default\: False)]:pipeline.model.use-gradient-scaling:(True False)"
  "--pipeline.model.implementation[Which implementation to use for the model. (default\: tcnn)]:pipeline.model.implementation:(torch tcnn)"
  "--pipeline.model.appearance-embed-dim[Dimension of the appearance embedding. (default\: 32)]:pipeline.model.appearance-embed-dim:"
  "--pipeline.model.depth-loss-mult[Lambda of the depth loss. (default\: 0.001)]:pipeline.model.depth-loss-mult:"
  "--pipeline.model.is-euclidean-depth[Whether input depth maps are Euclidean distances (or z-distances). (default\: False)]:pipeline.model.is-euclidean-depth:(True False)"
  "--pipeline.model.depth-sigma[Uncertainty around depth values in meters (defaults to 1cm). (default\: 0.01)]:pipeline.model.depth-sigma:"
  "--pipeline.model.should-decay-sigma[Whether to exponentially decay sigma. (default\: False)]:pipeline.model.should-decay-sigma:(True False)"
  "--pipeline.model.starting-depth-sigma[Starting uncertainty around depth values in meters (defaults to 0.2m). (default\: 0.2)]:pipeline.model.starting-depth-sigma:"
  "--pipeline.model.sigma-decay-rate[Rate of exponential decay. (default\: 0.99985)]:pipeline.model.sigma-decay-rate:"
  "--pipeline.model.depth-loss-type[Depth loss type. (default\: DS_NERF)]:pipeline.model.depth-loss-type:(URF DS_NERF SPARSENERF_RANKING)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_depth_nerfacto_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_depth_nerfacto_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_depth_nerfacto_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_depth_nerfacto_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_depth_nerfacto_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_depth_nerfacto_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_depth_nerfacto_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_depth_nerfacto_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_depth_nerfacto_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_depth_nerfacto_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_depth_nerfacto_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_depth_nerfacto_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_depth_nerfacto_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_depth_nerfacto_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_dnerf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: dnerf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 1024)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.num-coarse-samples[Number of samples in coarse field evaluation (default\: 64)]:pipeline.model.num-coarse-samples:"
  "--pipeline.model.num-importance-samples[Number of samples in fine field evaluation (default\: 128)]:pipeline.model.num-importance-samples:"
  "--pipeline.model.enable-temporal-distortion[Specifies whether or not to include ray warping based on time. (default\: True)]:pipeline.model.enable-temporal-distortion:(True False)"
  "--pipeline.model.temporal-distortion-params.kind[(default\: DNERF)]:pipeline.model.temporal-distortion-params.kind:(DNERF)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--optimizers.temporal-distortion.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.temporal-distortion.optimizer.lr:"
  "--optimizers.temporal-distortion.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.temporal-distortion.optimizer.eps:"
  "--optimizers.temporal-distortion.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.temporal-distortion.optimizer.max-norm:"
  "--optimizers.temporal-distortion.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.temporal-distortion.optimizer.weight-decay:"
  "--optimizers.temporal-distortion.scheduler[(default\: None)]:optimizers.temporal-distortion.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_dnerf_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_dnerf_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_dnerf_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_dnerf_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_dnerf_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_dnerf_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_dnerf_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_dnerf_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_dnerf_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_dnerf_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_dnerf_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_dnerf_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_dnerf_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_dnerf_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_generfacto_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: generfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: \'\')]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-resolution[Training resolution (default\: 64)]:pipeline.datamanager.train-resolution:"
  "--pipeline.datamanager.eval-resolution[Evaluation resolution (default\: 64)]:pipeline.datamanager.eval-resolution:"
  "--pipeline.datamanager.num-eval-angles[Number of evaluation angles (default\: 256)]:pipeline.datamanager.num-eval-angles:"
  "--pipeline.datamanager.train-images-per-batch[Number of images per batch for training (default\: 1)]:pipeline.datamanager.train-images-per-batch:"
  "--pipeline.datamanager.eval-images-per-batch[Number of images per batch for evaluation (default\: 1)]:pipeline.datamanager.eval-images-per-batch:"
  "--pipeline.datamanager.radius-mean[Mean radius of camera orbit (default\: 2.5)]:pipeline.datamanager.radius-mean:"
  "--pipeline.datamanager.radius-std[Std of radius of camera orbit (default\: 0.1)]:pipeline.datamanager.radius-std:"
  "--pipeline.datamanager.focal-range[Range of focal length (default\: 0.7 1.35)]:pipeline.datamanager.focal-range:"
  "--pipeline.datamanager.vertical-rotation-range[Range of vertical rotation (default\: -90 0)]:pipeline.datamanager.vertical-rotation-range:"
  "--pipeline.datamanager.jitter-std[Std of camera direction jitter, so we don\'t just point the cameras towards the center every time (default\: 0.05)]:pipeline.datamanager.jitter-std:"
  "--pipeline.datamanager.center[Center coordinate of the camera sphere (default\: 0 0 0)]:pipeline.datamanager.center:"
  "--pipeline.datamanager.horizontal-rotation-warmup[How many steps until the full horizontal rotation range is used (default\: 3000)]:pipeline.datamanager.horizontal-rotation-warmup:"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[prompt for stable dreamfusion (default\: \'a high quality photo of a ripe pineapple\')]:pipeline.model.prompt:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multipier on computed normals. (default\: 0.001 10.0)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.orientation-loss-mult-range[number of iterations to reach last orientation_loss_mult value (default\: 0 15000)]:pipeline.model.orientation-loss-mult-range:"
  "--pipeline.model.random-light-source[Randomizes light source per output. (default\: True)]:pipeline.model.random-light-source:(True False)"
  "--pipeline.model.initialize-density[Initialize density in center of scene. (default\: True)]:pipeline.model.initialize-density:(True False)"
  "--pipeline.model.taper-range[Range of step values for the density tapering (default\: 0 2000)]:pipeline.model.taper-range:"
  "--pipeline.model.taper-strength[Strength schedule of center density (default\: 1.0 0.0)]:pipeline.model.taper-strength:"
  "--pipeline.model.sphere-collider[Use spherical collider instead of box (default\: True)]:pipeline.model.sphere-collider:(True False)"
  "--pipeline.model.random-background[Randomly choose between using background mlp and random color for background (default\: True)]:pipeline.model.random-background:(True False)"
  "--pipeline.model.target-transmittance-start[target transmittance for opacity penalty. This is the percent of the scene that is background when rendered at the start of training (default\: 0.4)]:pipeline.model.target-transmittance-start:"
  "--pipeline.model.target-transmittance-end[target transmittance for opacity penalty. This is the percent of the scene that is background when rendered at the end of training (default\: 0.7)]:pipeline.model.target-transmittance-end:"
  "--pipeline.model.transmittance-end-schedule[number of iterations to reach target_transmittance_end (default\: 1500)]:pipeline.model.transmittance-end-schedule:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 0)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 2000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 2000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 100.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 1.0)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.start-normals-training[Start training normals after this many iterations (default\: 2000)]:pipeline.model.start-normals-training:"
  "--pipeline.model.start-lambertian-training[start training with lambertian shading after this many iterations (default\: 500)]:pipeline.model.start-lambertian-training:"
  "--pipeline.model.opacity-penalty[enables penalty to encourage sparse weights (penalizing for uniform density along ray) (default\: True)]:pipeline.model.opacity-penalty:(True False)"
  "--pipeline.model.opacity-loss-mult[scale for opacity penalty (default\: 0.001)]:pipeline.model.opacity-loss-mult:"
  "--pipeline.model.max-res[Maximum resolution of the density field. (default\: 256)]:pipeline.model.max-res:"
  "--pipeline.model.location-based-prompting[enables location based prompting (default\: True)]:pipeline.model.location-based-prompting:(True False)"
  "--pipeline.model.interpolated-prompting[enables interpolated location prompting (default\: False)]:pipeline.model.interpolated-prompting:(True False)"
  "--pipeline.model.positional-prompting[how to incorporate position into prompt (default\: discrete)]:pipeline.model.positional-prompting:(interpolated off discrete)"
  "--pipeline.model.top-prompt[appended to prompt for overhead view (default\: \', overhead view\')]:pipeline.model.top-prompt:"
  "--pipeline.model.side-prompt[appended to prompt for side view (default\: \', side view\')]:pipeline.model.side-prompt:"
  "--pipeline.model.front-prompt[appended to prompt for front view (default\: \', front view\')]:pipeline.model.front-prompt:"
  "--pipeline.model.back-prompt[appended to prompt for back view (default\: \', back view\')]:pipeline.model.back-prompt:"
  "--pipeline.model.guidance-scale[guidance scale for sds loss (default\: 25)]:pipeline.model.guidance-scale:"
  "--pipeline.model.diffusion-device[device for diffusion model (default\: None)]:pipeline.model.diffusion-device:"
  "--pipeline.model.diffusion-model[diffusion model for SDS loss (default\: deepfloyd)]:pipeline.model.diffusion-model:(stablediffusion deepfloyd)"
  "--pipeline.model.sd-version[model version when using stable diffusion (default\: 1-5)]:pipeline.model.sd-version:"
  "--pipeline.model.implementation[Which implementation to use for the model. (default\: tcnn)]:pipeline.model.implementation:(torch tcnn)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.001)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 200)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 50)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 50)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_generfacto_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_generfacto_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_in2n_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: in2n)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]Instruct-NeRF2NeRF\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/in2n.html

To enable Instruct-NeRF2NeRF, you must install it first by running\:
  \\\[grey\]pip install git\+https\:\/\/github.com\/ayaanzhaque\/instruct-nerf2nerf\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: in2n \'Instruct-NeRF2NeRF. Full model, used in paper\' in2n-small \'Instruct-NeRF2NeRF. Half precision model\' in2n-tiny \'Instruct-NeRF2NeRF. Half prevision with no LPIPS\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: git\+https\:\/\/github.com\/ayaanzhaque\/instruct-nerf2nerf)]:_method.pip-package:"
)

_shtab_tyro_ns_train_in2n_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_in2n_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_in2n_small_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: in2n-small)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]Instruct-NeRF2NeRF\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/in2n.html

To enable Instruct-NeRF2NeRF, you must install it first by running\:
  \\\[grey\]pip install git\+https\:\/\/github.com\/ayaanzhaque\/instruct-nerf2nerf\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: in2n \'Instruct-NeRF2NeRF. Full model, used in paper\' in2n-small \'Instruct-NeRF2NeRF. Half precision model\' in2n-tiny \'Instruct-NeRF2NeRF. Half prevision with no LPIPS\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: git\+https\:\/\/github.com\/ayaanzhaque\/instruct-nerf2nerf)]:_method.pip-package:"
)

_shtab_tyro_ns_train_in2n_small_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_in2n_small_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_in2n_tiny_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: in2n-tiny)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]Instruct-NeRF2NeRF\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/in2n.html

To enable Instruct-NeRF2NeRF, you must install it first by running\:
  \\\[grey\]pip install git\+https\:\/\/github.com\/ayaanzhaque\/instruct-nerf2nerf\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: in2n \'Instruct-NeRF2NeRF. Full model, used in paper\' in2n-small \'Instruct-NeRF2NeRF. Half precision model\' in2n-tiny \'Instruct-NeRF2NeRF. Half prevision with no LPIPS\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: git\+https\:\/\/github.com\/ayaanzhaque\/instruct-nerf2nerf)]:_method.pip-package:"
)

_shtab_tyro_ns_train_in2n_tiny_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_in2n_tiny_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_instant_ngp_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: instant-ngp)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 4096)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: False)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[Instant NGP doesn\'t use a collider. (default\: None)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 8192)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.grid-resolution[Resolution of the grid used for the field. (default\: 128)]:pipeline.model.grid-resolution:"
  "--pipeline.model.grid-levels[Levels of the grid used for the field. (default\: 4)]:pipeline.model.grid-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.alpha-thre[Threshold for opacity skipping. (default\: 0.01)]:pipeline.model.alpha-thre:"
  "--pipeline.model.cone-angle[Should be set to 0.0 for blender scenes but 1.\/256 for real scenes. (default\: 0.004)]:pipeline.model.cone-angle:"
  "--pipeline.model.render-step-size[Minimum step size for rendering. (default\: None)]:pipeline.model.render-step-size:"
  "--pipeline.model.near-plane[How far along ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.use-appearance-embedding[Whether to use an appearance embedding. (default\: False)]:pipeline.model.use-appearance-embedding:(True False)"
  "--pipeline.model.background-color[The color that is given to untrained areas. (default\: random)]:pipeline.model.background-color:(black white random)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.target-num-samples[The target number of samples to use for an entire batch of rays. (default\: 262144)]:pipeline.target-num-samples:"
  "--pipeline.max-num-samples-per-ray[The maximum number of samples to be placed along a ray. (default\: 1024)]:pipeline.max-num-samples-per-ray:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 200000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(cosine linear)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_instant_ngp_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: instant-ngp-bounded)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 4096)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 8192)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: False)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[Instant NGP doesn\'t use a collider. (default\: None)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 8192)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.grid-resolution[Resolution of the grid used for the field. (default\: 128)]:pipeline.model.grid-resolution:"
  "--pipeline.model.grid-levels[Levels of the grid used for the field. (default\: 1)]:pipeline.model.grid-levels:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.alpha-thre[Threshold for opacity skipping. (default\: 0.0)]:pipeline.model.alpha-thre:"
  "--pipeline.model.cone-angle[Should be set to 0.0 for blender scenes but 1.\/256 for real scenes. (default\: 0.0)]:pipeline.model.cone-angle:"
  "--pipeline.model.render-step-size[Minimum step size for rendering. (default\: None)]:pipeline.model.render-step-size:"
  "--pipeline.model.near-plane[How far along ray to start sampling. (default\: 0.01)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.use-appearance-embedding[Whether to use an appearance embedding. (default\: False)]:pipeline.model.use-appearance-embedding:(True False)"
  "--pipeline.model.background-color[The color that is given to untrained areas. (default\: black)]:pipeline.model.background-color:(black white random)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: True)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.target-num-samples[The target number of samples to use for an entire batch of rays. (default\: 262144)]:pipeline.target-num-samples:"
  "--pipeline.max-num-samples-per-ray[The maximum number of samples to be placed along a ray. (default\: 1024)]:pipeline.max-num-samples-per-ray:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 200000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(cosine linear)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_instant_ngp_bounded_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_bounded_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_bounded_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_bounded_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_bounded_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_bounded_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_instant_ngp_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_instant_ngp_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_instant_ngp_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_instant_ngp_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_instant_ngp_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_instant_ngp_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_instant_ngp_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_instant_ngp_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_kplanes_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: kplanes)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]K-Planes\\\[\/bold yellow\]
For more information visit https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/kplanes.html

To enable K-Planes, you must install it first by running\:
  \\\[grey\]pip install kplanes-nerfstudio\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: kplanes \'K-Planes model tuned to static blender scenes\' kplanes-dynamic \'K-Planes model tuned to dynamic DNeRF scenes\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: kplanes-nerfstudio)]:_method.pip-package:"
)

_shtab_tyro_ns_train_kplanes_dynamic_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: kplanes-dynamic)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]K-Planes\\\[\/bold yellow\]
For more information visit https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/kplanes.html

To enable K-Planes, you must install it first by running\:
  \\\[grey\]pip install kplanes-nerfstudio\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: kplanes \'K-Planes model tuned to static blender scenes\' kplanes-dynamic \'K-Planes model tuned to dynamic DNeRF scenes\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: kplanes-nerfstudio)]:_method.pip-package:"
)

_shtab_tyro_ns_train_kplanes_dynamic_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_kplanes_dynamic_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_kplanes_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_kplanes_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_lerf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: lerf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]LERF\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/lerf.html

To enable LERF, you must install it first by running\:
  \\\[grey\]pip install git\+https\:\/\/github.com\/kerrj\/lerf\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: lerf-big \'LERF with OpenCLIP ViT-L\/14\' lerf \'LERF with OpenCLIP ViT-B\/16, used in paper\' lerf-lite \'LERF with smaller network and less LERF samples\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: git\+https\:\/\/github.com\/kerrj\/lerf)]:_method.pip-package:"
)

_shtab_tyro_ns_train_lerf_big_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: lerf-big)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]LERF\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/lerf.html

To enable LERF, you must install it first by running\:
  \\\[grey\]pip install git\+https\:\/\/github.com\/kerrj\/lerf\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: lerf-big \'LERF with OpenCLIP ViT-L\/14\' lerf \'LERF with OpenCLIP ViT-B\/16, used in paper\' lerf-lite \'LERF with smaller network and less LERF samples\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: git\+https\:\/\/github.com\/kerrj\/lerf)]:_method.pip-package:"
)

_shtab_tyro_ns_train_lerf_big_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_lerf_big_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_lerf_lite_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: lerf-lite)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]LERF\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/lerf.html

To enable LERF, you must install it first by running\:
  \\\[grey\]pip install git\+https\:\/\/github.com\/kerrj\/lerf\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: lerf-big \'LERF with OpenCLIP ViT-L\/14\' lerf \'LERF with OpenCLIP ViT-B\/16, used in paper\' lerf-lite \'LERF with smaller network and less LERF samples\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: git\+https\:\/\/github.com\/kerrj\/lerf)]:_method.pip-package:"
)

_shtab_tyro_ns_train_lerf_lite_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_lerf_lite_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_lerf_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_lerf_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_mipnerf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: mipnerf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 1024)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 0.1)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 1024)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.num-coarse-samples[Number of samples in coarse field evaluation (default\: 128)]:pipeline.model.num-coarse-samples:"
  "--pipeline.model.num-importance-samples[Number of samples in fine field evaluation (default\: 128)]:pipeline.model.num-importance-samples:"
  "--pipeline.model.enable-temporal-distortion[Specifies whether or not to include ray warping based on time. (default\: False)]:pipeline.model.enable-temporal-distortion:(True False)"
  "--pipeline.model.temporal-distortion-params.kind[(default\: DNERF)]:pipeline.model.temporal-distortion-params.kind:(DNERF)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_mipnerf_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_mipnerf_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_mipnerf_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_mipnerf_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_mipnerf_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_mipnerf_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_mipnerf_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_mipnerf_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_mipnerf_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_mipnerf_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_mipnerf_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_mipnerf_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_mipnerf_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_mipnerf_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfacto_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: nerfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 6e-06)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 200000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(last_sample black white random)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.base-res[Resolution of the base grid for the hashgrid. (default\: 16)]:pipeline.model.base-res:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.features-per-level[How many hashgrid features per level (default\: 2)]:pipeline.model.features-per-level:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(uniform piecewise)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.use-gradient-scaling[Use gradient scaler where the gradients are lower for points closer to the camera. (default\: False)]:pipeline.model.use-gradient-scaling:(True False)"
  "--pipeline.model.implementation[Which implementation to use for the model. (default\: tcnn)]:pipeline.model.implementation:(torch tcnn)"
  "--pipeline.model.appearance-embed-dim[Dimension of the appearance embedding. (default\: 32)]:pipeline.model.appearance-embed-dim:"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.proposal-networks.scheduler.lr-pre-warmup:"
  "--optimizers.proposal-networks.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.proposal-networks.scheduler.lr-final:"
  "--optimizers.proposal-networks.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.proposal-networks.scheduler.warmup-steps:"
  "--optimizers.proposal-networks.scheduler.max-steps[The maximum number of steps. (default\: 200000)]:optimizers.proposal-networks.scheduler.max-steps:"
  "--optimizers.proposal-networks.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.proposal-networks.scheduler.ramp:(cosine linear)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 200000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(cosine linear)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_nerfacto_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_big_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: nerfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.001)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 8192)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(last_sample black white random)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 128)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 128)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.base-res[Resolution of the base grid for the hashgrid. (default\: 16)]:pipeline.model.base-res:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 4096)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 21)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.features-per-level[How many hashgrid features per level (default\: 2)]:pipeline.model.features-per-level:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 512 256)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 128)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(uniform piecewise)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 5000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.use-gradient-scaling[Use gradient scaler where the gradients are lower for points closer to the camera. (default\: False)]:pipeline.model.use-gradient-scaling:(True False)"
  "--pipeline.model.implementation[Which implementation to use for the model. (default\: tcnn)]:pipeline.model.implementation:(torch tcnn)"
  "--pipeline.model.appearance-embed-dim[Dimension of the appearance embedding. (default\: 128)]:pipeline.model.appearance-embed-dim:"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 50000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(cosine linear)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 100000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_nerfacto_big_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_big_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_big_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_nerfacto_big_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_big_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_nerfacto_big_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_nerfacto_big_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_nerfacto_big_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_big_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_big_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_nerfacto_big_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_big_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_big_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_nerfacto_big_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfacto_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_nerfacto_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_nerfacto_huge_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: nerfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.001)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 6e-05)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 50000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 16384)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(last_sample black white random)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 256)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 256)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.base-res[Resolution of the base grid for the hashgrid. (default\: 16)]:pipeline.model.base-res:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 8192)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 21)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.features-per-level[How many hashgrid features per level (default\: 2)]:pipeline.model.features-per-level:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 512 512)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 64)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 512)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 7)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 2048)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(uniform piecewise)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 5000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.use-gradient-scaling[Use gradient scaler where the gradients are lower for points closer to the camera. (default\: False)]:pipeline.model.use-gradient-scaling:(True False)"
  "--pipeline.model.implementation[Which implementation to use for the model. (default\: tcnn)]:pipeline.model.implementation:(torch tcnn)"
  "--pipeline.model.appearance-embed-dim[Dimension of the appearance embedding. (default\: 32)]:pipeline.model.appearance-embed-dim:"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 50000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(cosine linear)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 100000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_nerfacto_huge_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_huge_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_huge_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_nerfacto_huge_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_nerfacto_huge_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_nerfacto_huge_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_nerfacto_huge_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_nerfacto_huge_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_huge_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_huge_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_nerfacto_huge_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_huge_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_huge_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_nerfacto_huge_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfacto_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_nerfacto_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_nerfacto_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_nerfacto_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_nerfacto_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_nerfacto_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_nerfacto_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: nerfplayer-nerfacto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]NeRFPlayer\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/nerfplayer.html

To enable NeRFPlayer, you must install it first by running\:
  \\\[grey\]pip install git\+https\:\/\/github.com\/lsongx\/nerfplayer-nerfstudio\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: nerfplayer-nerfacto \'NeRFPlayer with nerfacto backbone\' nerfplayer-ngp \'NeRFPlayer with instang-ngp-bounded backbone\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: None)]:_method.pip-package:"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_nerfplayer_nerfacto_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_nerfplayer_ngp_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: nerfplayer-ngp)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]NeRFPlayer\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/nerfplayer.html

To enable NeRFPlayer, you must install it first by running\:
  \\\[grey\]pip install git\+https\:\/\/github.com\/lsongx\/nerfplayer-nerfstudio\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: nerfplayer-nerfacto \'NeRFPlayer with nerfacto backbone\' nerfplayer-ngp \'NeRFPlayer with instang-ngp-bounded backbone\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: None)]:_method.pip-package:"
)

_shtab_tyro_ns_train_nerfplayer_ngp_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_nerfplayer_ngp_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_neus_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: neus)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 1024)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 1024)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 4.0)]:pipeline.model.far-plane:"
  "--pipeline.model.far-plane-bg[How far along the ray to stop sampling of the background model. (default\: 1000.0)]:pipeline.model.far-plane-bg:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: black)]:pipeline.model.background-color:(last_sample black white random)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: False)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.eikonal-loss-mult[Monocular normal consistency loss multiplier. (default\: 0.1)]:pipeline.model.eikonal-loss-mult:"
  "--pipeline.model.fg-mask-loss-mult[Foreground mask loss multiplier. (default\: 0.01)]:pipeline.model.fg-mask-loss-mult:"
  "--pipeline.model.mono-normal-loss-mult[Monocular normal consistency loss multiplier. (default\: 0.0)]:pipeline.model.mono-normal-loss-mult:"
  "--pipeline.model.mono-depth-loss-mult[Monocular depth consistency loss multiplier. (default\: 0.0)]:pipeline.model.mono-depth-loss-mult:"
  "--pipeline.model.sdf-field.num-layers[Number of layers for geometric network (default\: 8)]:pipeline.model.sdf-field.num-layers:"
  "--pipeline.model.sdf-field.hidden-dim[Number of hidden dimension of geometric network (default\: 256)]:pipeline.model.sdf-field.hidden-dim:"
  "--pipeline.model.sdf-field.geo-feat-dim[Dimension of geometric feature (default\: 256)]:pipeline.model.sdf-field.geo-feat-dim:"
  "--pipeline.model.sdf-field.num-layers-color[Number of layers for color network (default\: 4)]:pipeline.model.sdf-field.num-layers-color:"
  "--pipeline.model.sdf-field.hidden-dim-color[Number of hidden dimension of color network (default\: 256)]:pipeline.model.sdf-field.hidden-dim-color:"
  "--pipeline.model.sdf-field.appearance-embedding-dim[Dimension of appearance embedding (default\: 32)]:pipeline.model.sdf-field.appearance-embedding-dim:"
  "--pipeline.model.sdf-field.use-appearance-embedding[Whether to use appearance embedding (default\: False)]:pipeline.model.sdf-field.use-appearance-embedding:(True False)"
  "--pipeline.model.sdf-field.bias[Sphere size of geometric initialization (default\: 0.8)]:pipeline.model.sdf-field.bias:"
  "--pipeline.model.sdf-field.geometric-init[Whether to use geometric initialization (default\: True)]:pipeline.model.sdf-field.geometric-init:(True False)"
  "--pipeline.model.sdf-field.inside-outside[Whether to revert signed distance value, set to True for indoor scene (default\: True)]:pipeline.model.sdf-field.inside-outside:(True False)"
  "--pipeline.model.sdf-field.weight-norm[Whether to use weight norm for linear layer (default\: True)]:pipeline.model.sdf-field.weight-norm:(True False)"
  "--pipeline.model.sdf-field.use-grid-feature[Whether to use multi-resolution feature grids (default\: False)]:pipeline.model.sdf-field.use-grid-feature:(True False)"
  "--pipeline.model.sdf-field.divide-factor[Normalization factor for multi-resolution grids (default\: 2.0)]:pipeline.model.sdf-field.divide-factor:"
  "--pipeline.model.sdf-field.beta-init[Init learnable beta value for transformation of sdf to density (default\: 0.1)]:pipeline.model.sdf-field.beta-init:"
  "--pipeline.model.sdf-field.encoding-type[(default\: hash)]:pipeline.model.sdf-field.encoding-type:(periodic hash tensorf_vm)"
  "--pipeline.model.sdf-field.num-levels[Number of encoding levels (default\: 16)]:pipeline.model.sdf-field.num-levels:"
  "--pipeline.model.sdf-field.max-res[Maximum resolution of the encoding (default\: 2048)]:pipeline.model.sdf-field.max-res:"
  "--pipeline.model.sdf-field.base-res[Base resolution of the encoding (default\: 16)]:pipeline.model.sdf-field.base-res:"
  "--pipeline.model.sdf-field.log2-hashmap-size[Size of the hash map (default\: 19)]:pipeline.model.sdf-field.log2-hashmap-size:"
  "--pipeline.model.sdf-field.features-per-level[Number of features per encoding level (default\: 2)]:pipeline.model.sdf-field.features-per-level:"
  "--pipeline.model.sdf-field.use-hash[Whether to use hash encoding (default\: True)]:pipeline.model.sdf-field.use-hash:(True False)"
  "--pipeline.model.sdf-field.smoothstep[Whether to use the smoothstep function (default\: True)]:pipeline.model.sdf-field.smoothstep:(True False)"
  "--pipeline.model.background-model[background models (default\: mlp)]:pipeline.model.background-model:(grid mlp none)"
  "--pipeline.model.num-samples-outside[Number of samples outside the bounding sphere for background (default\: 32)]:pipeline.model.num-samples-outside:"
  "--pipeline.model.periodic-tvl-mult[Total variational loss multiplier (default\: 0.0)]:pipeline.model.periodic-tvl-mult:"
  "--pipeline.model.overwrite-near-far-plane[whether to use near and far collider from command line (default\: False)]:pipeline.model.overwrite-near-far-plane:(True False)"
  "--pipeline.model.num-samples[Number of uniform samples (default\: 64)]:pipeline.model.num-samples:"
  "--pipeline.model.num-samples-importance[Number of importance samples (default\: 64)]:pipeline.model.num-samples-importance:"
  "--pipeline.model.num-up-sample-steps[number of up sample step, 1 for simple coarse-to-fine sampling (default\: 4)]:pipeline.model.num-up-sample-steps:"
  "--pipeline.model.base-variance[fixed base variance in NeuS sampler, the inv_s will be base \* 2 \*\* iter during upsample (default\: 64)]:pipeline.model.base-variance:"
  "--pipeline.model.perturb[use to use perturb for the sampled points (default\: True)]:pipeline.model.perturb:(True False)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.warm-up-end[Iteration number where warmp ends (default\: 5000)]:optimizers.fields.scheduler.warm-up-end:"
  "--optimizers.fields.scheduler.learning-rate-alpha[Learning rate alpha value (default\: 0.05)]:optimizers.fields.scheduler.learning-rate-alpha:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 300000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.field-background.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.field-background.optimizer.lr:"
  "--optimizers.field-background.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.field-background.optimizer.eps:"
  "--optimizers.field-background.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.field-background.optimizer.max-norm:"
  "--optimizers.field-background.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.field-background.optimizer.weight-decay:"
  "--optimizers.field-background.scheduler.warm-up-end[Iteration number where warmp ends (default\: 5000)]:optimizers.field-background.scheduler.warm-up-end:"
  "--optimizers.field-background.scheduler.learning-rate-alpha[Learning rate alpha value (default\: 0.05)]:optimizers.field-background.scheduler.learning-rate-alpha:"
  "--optimizers.field-background.scheduler.max-steps[The maximum number of steps. (default\: 300000)]:optimizers.field-background.scheduler.max-steps:"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 20000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 5000)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 1000000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 100000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_neus_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_neus_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_neus_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_neus_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_neus_facto_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: neus-facto)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 2048)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 2048)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 2048)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 4.0)]:pipeline.model.far-plane:"
  "--pipeline.model.far-plane-bg[How far along the ray to stop sampling of the background model. (default\: 1000.0)]:pipeline.model.far-plane-bg:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: black)]:pipeline.model.background-color:(last_sample black white random)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: False)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.eikonal-loss-mult[Monocular normal consistency loss multiplier. (default\: 0.1)]:pipeline.model.eikonal-loss-mult:"
  "--pipeline.model.fg-mask-loss-mult[Foreground mask loss multiplier. (default\: 0.01)]:pipeline.model.fg-mask-loss-mult:"
  "--pipeline.model.mono-normal-loss-mult[Monocular normal consistency loss multiplier. (default\: 0.0)]:pipeline.model.mono-normal-loss-mult:"
  "--pipeline.model.mono-depth-loss-mult[Monocular depth consistency loss multiplier. (default\: 0.0)]:pipeline.model.mono-depth-loss-mult:"
  "--pipeline.model.sdf-field.num-layers[Number of layers for geometric network (default\: 2)]:pipeline.model.sdf-field.num-layers:"
  "--pipeline.model.sdf-field.hidden-dim[Number of hidden dimension of geometric network (default\: 256)]:pipeline.model.sdf-field.hidden-dim:"
  "--pipeline.model.sdf-field.geo-feat-dim[Dimension of geometric feature (default\: 256)]:pipeline.model.sdf-field.geo-feat-dim:"
  "--pipeline.model.sdf-field.num-layers-color[Number of layers for color network (default\: 2)]:pipeline.model.sdf-field.num-layers-color:"
  "--pipeline.model.sdf-field.hidden-dim-color[Number of hidden dimension of color network (default\: 256)]:pipeline.model.sdf-field.hidden-dim-color:"
  "--pipeline.model.sdf-field.appearance-embedding-dim[Dimension of appearance embedding (default\: 32)]:pipeline.model.sdf-field.appearance-embedding-dim:"
  "--pipeline.model.sdf-field.use-appearance-embedding[Whether to use appearance embedding (default\: False)]:pipeline.model.sdf-field.use-appearance-embedding:(True False)"
  "--pipeline.model.sdf-field.bias[Sphere size of geometric initialization (default\: 0.5)]:pipeline.model.sdf-field.bias:"
  "--pipeline.model.sdf-field.geometric-init[Whether to use geometric initialization (default\: True)]:pipeline.model.sdf-field.geometric-init:(True False)"
  "--pipeline.model.sdf-field.inside-outside[Whether to revert signed distance value, set to True for indoor scene (default\: True)]:pipeline.model.sdf-field.inside-outside:(True False)"
  "--pipeline.model.sdf-field.weight-norm[Whether to use weight norm for linear layer (default\: True)]:pipeline.model.sdf-field.weight-norm:(True False)"
  "--pipeline.model.sdf-field.use-grid-feature[Whether to use multi-resolution feature grids (default\: True)]:pipeline.model.sdf-field.use-grid-feature:(True False)"
  "--pipeline.model.sdf-field.divide-factor[Normalization factor for multi-resolution grids (default\: 2.0)]:pipeline.model.sdf-field.divide-factor:"
  "--pipeline.model.sdf-field.beta-init[Init learnable beta value for transformation of sdf to density (default\: 0.8)]:pipeline.model.sdf-field.beta-init:"
  "--pipeline.model.sdf-field.encoding-type[(default\: hash)]:pipeline.model.sdf-field.encoding-type:(periodic hash tensorf_vm)"
  "--pipeline.model.sdf-field.num-levels[Number of encoding levels (default\: 16)]:pipeline.model.sdf-field.num-levels:"
  "--pipeline.model.sdf-field.max-res[Maximum resolution of the encoding (default\: 2048)]:pipeline.model.sdf-field.max-res:"
  "--pipeline.model.sdf-field.base-res[Base resolution of the encoding (default\: 16)]:pipeline.model.sdf-field.base-res:"
  "--pipeline.model.sdf-field.log2-hashmap-size[Size of the hash map (default\: 19)]:pipeline.model.sdf-field.log2-hashmap-size:"
  "--pipeline.model.sdf-field.features-per-level[Number of features per encoding level (default\: 2)]:pipeline.model.sdf-field.features-per-level:"
  "--pipeline.model.sdf-field.use-hash[Whether to use hash encoding (default\: True)]:pipeline.model.sdf-field.use-hash:(True False)"
  "--pipeline.model.sdf-field.smoothstep[Whether to use the smoothstep function (default\: True)]:pipeline.model.sdf-field.smoothstep:(True False)"
  "--pipeline.model.background-model[background models (default\: none)]:pipeline.model.background-model:(grid mlp none)"
  "--pipeline.model.num-samples-outside[Number of samples outside the bounding sphere for background (default\: 32)]:pipeline.model.num-samples-outside:"
  "--pipeline.model.periodic-tvl-mult[Total variational loss multiplier (default\: 0.0)]:pipeline.model.periodic-tvl-mult:"
  "--pipeline.model.overwrite-near-far-plane[whether to use near and far collider from command line (default\: False)]:pipeline.model.overwrite-near-far-plane:(True False)"
  "--pipeline.model.num-samples[Number of uniform samples (default\: 64)]:pipeline.model.num-samples:"
  "--pipeline.model.num-samples-importance[Number of importance samples (default\: 64)]:pipeline.model.num-samples-importance:"
  "--pipeline.model.num-up-sample-steps[number of up sample step, 1 for simple coarse-to-fine sampling (default\: 4)]:pipeline.model.num-up-sample-steps:"
  "--pipeline.model.base-variance[fixed base variance in NeuS sampler, the inv_s will be base \* 2 \*\* iter during upsample (default\: 64)]:pipeline.model.base-variance:"
  "--pipeline.model.perturb[use to use perturb for the sampled points (default\: True)]:pipeline.model.perturb:(True False)"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for the proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-neus-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-neus-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 64)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler.max-steps[The maximum number of steps. (default\: 20001)]:optimizers.proposal-networks.scheduler.max-steps:"
  "--optimizers.proposal-networks.scheduler.gamma[The learning rate decay factor. (default\: 0.33)]:optimizers.proposal-networks.scheduler.gamma:"
  "--optimizers.proposal-networks.scheduler.milestones[The milestone steps at which to decay the learning rate. (default\: 10000 1500 18000)]:optimizers.proposal-networks.scheduler.milestones:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.warm-up-end[Iteration number where warmp ends (default\: 500)]:optimizers.fields.scheduler.warm-up-end:"
  "--optimizers.fields.scheduler.learning-rate-alpha[Learning rate alpha value (default\: 0.05)]:optimizers.fields.scheduler.learning-rate-alpha:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 20001)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.field-background.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.field-background.optimizer.lr:"
  "--optimizers.field-background.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.field-background.optimizer.eps:"
  "--optimizers.field-background.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.field-background.optimizer.max-norm:"
  "--optimizers.field-background.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.field-background.optimizer.weight-decay:"
  "--optimizers.field-background.scheduler.warm-up-end[Iteration number where warmp ends (default\: 500)]:optimizers.field-background.scheduler.warm-up-end:"
  "--optimizers.field-background.scheduler.learning-rate-alpha[Learning rate alpha value (default\: 0.05)]:optimizers.field-background.scheduler.learning-rate-alpha:"
  "--optimizers.field-background.scheduler.max-steps[The maximum number of steps. (default\: 20001)]:optimizers.field-background.scheduler.max-steps:"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 5000)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 5000)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 1000000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 20001)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_neus_facto_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_facto_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_neus_facto_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_neus_facto_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_neus_facto_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_neus_facto_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_neus_facto_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_neus_facto_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_neus_facto_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_facto_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_neus_facto_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_neus_facto_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_facto_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_neus_facto_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_neus_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_neus_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_neus_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_neus_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_neus_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_neus_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_neus_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_neus_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_phototourism_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: phototourism)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: SO3xR3)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0.01)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: 40)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: 100)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: 40)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: 100)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(last_sample black white random)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.base-res[Resolution of the base grid for the hashgrid. (default\: 16)]:pipeline.model.base-res:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.features-per-level[How many hashgrid features per level (default\: 2)]:pipeline.model.features-per-level:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(uniform piecewise)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.use-gradient-scaling[Use gradient scaler where the gradients are lower for points closer to the camera. (default\: False)]:pipeline.model.use-gradient-scaling:(True False)"
  "--pipeline.model.implementation[Which implementation to use for the model. (default\: tcnn)]:pipeline.model.implementation:(torch tcnn)"
  "--pipeline.model.appearance-embed-dim[Dimension of the appearance embedding. (default\: 32)]:pipeline.model.appearance-embed-dim:"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_phototourism_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_phototourism_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_phototourism_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_phototourism_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_phototourism_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_phototourism_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_phototourism_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_phototourism_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_phototourism_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_phototourism_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_phototourism_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_phototourism_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_phototourism_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_phototourism_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_reconstruction_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: reconstruction)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 32768)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(last_sample black white random)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.base-res[Resolution of the base grid for the hashgrid. (default\: 16)]:pipeline.model.base-res:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.features-per-level[How many hashgrid features per level (default\: 2)]:pipeline.model.features-per-level:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(uniform piecewise)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.use-gradient-scaling[Use gradient scaler where the gradients are lower for points closer to the camera. (default\: False)]:pipeline.model.use-gradient-scaling:(True False)"
  "--pipeline.model.implementation[Which implementation to use for the model. (default\: tcnn)]:pipeline.model.implementation:(torch tcnn)"
  "--pipeline.model.appearance-embed-dim[Dimension of the appearance embedding. (default\: 32)]:pipeline.model.appearance-embed-dim:"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.proposal-networks.scheduler.lr-pre-warmup:"
  "--optimizers.proposal-networks.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.proposal-networks.scheduler.lr-final:"
  "--optimizers.proposal-networks.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.proposal-networks.scheduler.warmup-steps:"
  "--optimizers.proposal-networks.scheduler.max-steps[The maximum number of steps. (default\: 200000)]:optimizers.proposal-networks.scheduler.max-steps:"
  "--optimizers.proposal-networks.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.proposal-networks.scheduler.ramp:(cosine linear)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 50000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(cosine linear)"
  "--optimizers.camera-opt.optimizer.lr[The learning rate to use. (default\: 0.001)]:optimizers.camera-opt.optimizer.lr:"
  "--optimizers.camera-opt.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.camera-opt.optimizer.eps:"
  "--optimizers.camera-opt.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.camera-opt.optimizer.max-norm:"
  "--optimizers.camera-opt.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.camera-opt.optimizer.weight-decay:"
  "--optimizers.camera-opt.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.camera-opt.scheduler.lr-pre-warmup:"
  "--optimizers.camera-opt.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.camera-opt.scheduler.lr-final:"
  "--optimizers.camera-opt.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.camera-opt.scheduler.warmup-steps:"
  "--optimizers.camera-opt.scheduler.max-steps[The maximum number of steps. (default\: 5000)]:optimizers.camera-opt.scheduler.max-steps:"
  "--optimizers.camera-opt.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.camera-opt.scheduler.ramp:(cosine linear)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_reconstruction_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_reconstruction_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_reconstruction_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_reconstruction_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_reconstruction_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_reconstruction_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_reconstruction_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_reconstruction_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_reconstruction_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_reconstruction_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_reconstruction_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_reconstruction_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_reconstruction_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_reconstruction_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_semantic_nerfw_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: semantic-nerfw)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 65536)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 8192)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 65536)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.near-plane[How far along the ray to start sampling. (default\: 0.05)]:pipeline.model.near-plane:"
  "--pipeline.model.far-plane[How far along the ray to stop sampling. (default\: 1000.0)]:pipeline.model.far-plane:"
  "--pipeline.model.background-color[Whether to randomize the background color. (default\: last_sample)]:pipeline.model.background-color:(last_sample black white random)"
  "--pipeline.model.hidden-dim[Dimension of hidden layers (default\: 64)]:pipeline.model.hidden-dim:"
  "--pipeline.model.hidden-dim-color[Dimension of hidden layers for color network (default\: 64)]:pipeline.model.hidden-dim-color:"
  "--pipeline.model.hidden-dim-transient[Dimension of hidden layers for transient network (default\: 64)]:pipeline.model.hidden-dim-transient:"
  "--pipeline.model.num-levels[Number of levels of the hashmap for the base mlp. (default\: 16)]:pipeline.model.num-levels:"
  "--pipeline.model.base-res[Resolution of the base grid for the hashgrid. (default\: 16)]:pipeline.model.base-res:"
  "--pipeline.model.max-res[Maximum resolution of the hashmap for the base mlp. (default\: 2048)]:pipeline.model.max-res:"
  "--pipeline.model.log2-hashmap-size[Size of the hashmap for the base mlp (default\: 19)]:pipeline.model.log2-hashmap-size:"
  "--pipeline.model.features-per-level[How many hashgrid features per level (default\: 2)]:pipeline.model.features-per-level:"
  "--pipeline.model.num-proposal-samples-per-ray[Number of samples per ray for each proposal network. (default\: 256 96)]:pipeline.model.num-proposal-samples-per-ray:"
  "--pipeline.model.num-nerf-samples-per-ray[Number of samples per ray for the nerf network. (default\: 48)]:pipeline.model.num-nerf-samples-per-ray:"
  "--pipeline.model.proposal-update-every[Sample every n steps after the warmup (default\: 5)]:pipeline.model.proposal-update-every:"
  "--pipeline.model.proposal-warmup[Scales n from 1 to proposal_update_every over this many steps (default\: 5000)]:pipeline.model.proposal-warmup:"
  "--pipeline.model.num-proposal-iterations[Number of proposal network iterations. (default\: 2)]:pipeline.model.num-proposal-iterations:"
  "--pipeline.model.use-same-proposal-network[Use the same proposal network. Otherwise use different ones. (default\: False)]:pipeline.model.use-same-proposal-network:(True False)"
  "--pipeline.model.proposal-net-args-list.0.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.0.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.0.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.0.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.0.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.0.num-levels:"
  "--pipeline.model.proposal-net-args-list.0.max-res[(default\: 128)]:pipeline.model.proposal-net-args-list.0.max-res:"
  "--pipeline.model.proposal-net-args-list.0.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.0.use-linear:(True False)"
  "--pipeline.model.proposal-net-args-list.1.hidden-dim[(default\: 16)]:pipeline.model.proposal-net-args-list.1.hidden-dim:"
  "--pipeline.model.proposal-net-args-list.1.log2-hashmap-size[(default\: 17)]:pipeline.model.proposal-net-args-list.1.log2-hashmap-size:"
  "--pipeline.model.proposal-net-args-list.1.num-levels[(default\: 5)]:pipeline.model.proposal-net-args-list.1.num-levels:"
  "--pipeline.model.proposal-net-args-list.1.max-res[(default\: 256)]:pipeline.model.proposal-net-args-list.1.max-res:"
  "--pipeline.model.proposal-net-args-list.1.use-linear[(default\: False)]:pipeline.model.proposal-net-args-list.1.use-linear:(True False)"
  "--pipeline.model.proposal-initial-sampler[Initial sampler for the proposal network. Piecewise is preferred for unbounded scenes. (default\: piecewise)]:pipeline.model.proposal-initial-sampler:(uniform piecewise)"
  "--pipeline.model.interlevel-loss-mult[Proposal loss multiplier. (default\: 1.0)]:pipeline.model.interlevel-loss-mult:"
  "--pipeline.model.distortion-loss-mult[Distortion loss multiplier. (default\: 0.002)]:pipeline.model.distortion-loss-mult:"
  "--pipeline.model.orientation-loss-mult[Orientation loss multiplier on computed normals. (default\: 0.0001)]:pipeline.model.orientation-loss-mult:"
  "--pipeline.model.pred-normal-loss-mult[Predicted normal loss multiplier. (default\: 0.001)]:pipeline.model.pred-normal-loss-mult:"
  "--pipeline.model.use-proposal-weight-anneal[Whether to use proposal weight annealing. (default\: True)]:pipeline.model.use-proposal-weight-anneal:(True False)"
  "--pipeline.model.use-average-appearance-embedding[Whether to use average appearance embedding or zeros for inference. (default\: True)]:pipeline.model.use-average-appearance-embedding:(True False)"
  "--pipeline.model.proposal-weights-anneal-slope[Slope of the annealing function for the proposal weights. (default\: 10.0)]:pipeline.model.proposal-weights-anneal-slope:"
  "--pipeline.model.proposal-weights-anneal-max-num-iters[Max num iterations for the annealing function. (default\: 1000)]:pipeline.model.proposal-weights-anneal-max-num-iters:"
  "--pipeline.model.use-single-jitter[Whether use single jitter or not for the proposal networks. (default\: True)]:pipeline.model.use-single-jitter:(True False)"
  "--pipeline.model.predict-normals[Whether to predict normals or not. (default\: False)]:pipeline.model.predict-normals:(True False)"
  "--pipeline.model.disable-scene-contraction[Whether to disable scene contraction or not. (default\: False)]:pipeline.model.disable-scene-contraction:(True False)"
  "--pipeline.model.use-gradient-scaling[Use gradient scaler where the gradients are lower for points closer to the camera. (default\: False)]:pipeline.model.use-gradient-scaling:(True False)"
  "--pipeline.model.implementation[Which implementation to use for the model. (default\: tcnn)]:pipeline.model.implementation:(torch tcnn)"
  "--pipeline.model.appearance-embed-dim[Dimension of the appearance embedding. (default\: 32)]:pipeline.model.appearance-embed-dim:"
  "--pipeline.model.use-transient-embedding[Whether to use transient embedding. (default\: False)]:pipeline.model.use-transient-embedding:(True False)"
  "--pipeline.model.semantic-loss-weight[(default\: 1.0)]:pipeline.model.semantic-loss-weight:"
  "--pipeline.model.pass-semantic-gradients[(default\: False)]:pipeline.model.pass-semantic-gradients:(True False)"
  "--optimizers.proposal-networks.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.proposal-networks.optimizer.lr:"
  "--optimizers.proposal-networks.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.proposal-networks.optimizer.eps:"
  "--optimizers.proposal-networks.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.proposal-networks.optimizer.max-norm:"
  "--optimizers.proposal-networks.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.proposal-networks.optimizer.weight-decay:"
  "--optimizers.proposal-networks.scheduler[(default\: None)]:optimizers.proposal-networks.scheduler:(None)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.01)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: True)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_semantic_nerfw_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_semantic_nerfw_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_semantic_nerfw_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_semantic_nerfw_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_semantic_nerfw_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_semantic_nerfw_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_semantic_nerfw_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_semantic_nerfw_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_semantic_nerfw_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_semantic_nerfw_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_semantic_nerfw_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_semantic_nerfw_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_semantic_nerfw_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_semantic_nerfw_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_tensorf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: tensorf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 4096)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 4096)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss:"
  "--pipeline.model.loss-coefficients.tv-reg-density[(default\: 0.001)]:pipeline.model.loss-coefficients.tv-reg-density:"
  "--pipeline.model.loss-coefficients.tv-reg-color[(default\: 0.0001)]:pipeline.model.loss-coefficients.tv-reg-color:"
  "--pipeline.model.loss-coefficients.l1-reg[(default\: 0.0005)]:pipeline.model.loss-coefficients.l1-reg:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.init-resolution[initial render resolution (default\: 128)]:pipeline.model.init-resolution:"
  "--pipeline.model.final-resolution[final render resolution (default\: 300)]:pipeline.model.final-resolution:"
  "--pipeline.model.upsampling-iters[specifies a list of iteration step numbers to perform upsampling (default\: 2000 3000 4000 5500 7000)]:pipeline.model.upsampling-iters:"
  "--pipeline.model.num-samples[Number of samples in field evaluation (default\: 50)]:pipeline.model.num-samples:"
  "--pipeline.model.num-uniform-samples[Number of samples in density evaluation (default\: 200)]:pipeline.model.num-uniform-samples:"
  "--pipeline.model.num-den-components[Number of components in density encoding (default\: 16)]:pipeline.model.num-den-components:"
  "--pipeline.model.num-color-components[Number of components in color encoding (default\: 48)]:pipeline.model.num-color-components:"
  "--pipeline.model.appearance-dim[Number of channels for color encoding (default\: 27)]:pipeline.model.appearance-dim:"
  "--pipeline.model.tensorf-encoding[(default\: vm)]:pipeline.model.tensorf-encoding:(cp triplane vm)"
  "--pipeline.model.regularization[Regularization method used in tensorf paper (default\: tv)]:pipeline.model.regularization:(tv l1 none)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.001)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.fields.scheduler.lr-pre-warmup:"
  "--optimizers.fields.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.0001)]:optimizers.fields.scheduler.lr-final:"
  "--optimizers.fields.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.fields.scheduler.warmup-steps:"
  "--optimizers.fields.scheduler.max-steps[The maximum number of steps. (default\: 30000)]:optimizers.fields.scheduler.max-steps:"
  "--optimizers.fields.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.fields.scheduler.ramp:(cosine linear)"
  "--optimizers.encodings.optimizer.lr[The learning rate to use. (default\: 0.02)]:optimizers.encodings.optimizer.lr:"
  "--optimizers.encodings.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.encodings.optimizer.eps:"
  "--optimizers.encodings.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.encodings.optimizer.max-norm:"
  "--optimizers.encodings.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.encodings.optimizer.weight-decay:"
  "--optimizers.encodings.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:optimizers.encodings.scheduler.lr-pre-warmup:"
  "--optimizers.encodings.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: 0.002)]:optimizers.encodings.scheduler.lr-final:"
  "--optimizers.encodings.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:optimizers.encodings.scheduler.warmup-steps:"
  "--optimizers.encodings.scheduler.max-steps[The maximum number of steps. (default\: 30000)]:optimizers.encodings.scheduler.max-steps:"
  "--optimizers.encodings.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:optimizers.encodings.scheduler.ramp:(cosine linear)"
  "--vis[Which visualizer to use. (default\: viewer)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 2000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 30000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_tensorf_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_tensorf_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_tensorf_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_tensorf_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_tensorf_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_tensorf_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_tensorf_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_tensorf_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_tensorf_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_tensorf_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_tensorf_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_tensorf_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_tensorf_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_tensorf_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_tetra_nerf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: tetra-nerf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]Tetra-NeRF\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/tetranerf.html

To enable Tetra-NeRF, you must install it first. Please follow the instructions here\:
  https\:\/\/github.com\/jkulhanek\/tetra-nerf\/blob\/master\/README.md\#installation\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: tetra-nerf-original \'Tetra-NeRF. Official implementation from the paper\' tetra-nerf \'Tetra-NeRF. Different sampler - faster and better\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: None)]:_method.pip-package:"
)

_shtab_tyro_ns_train_tetra_nerf_original_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: tetra-nerf-original)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]Tetra-NeRF\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/nerfology\/methods\/tetranerf.html

To enable Tetra-NeRF, you must install it first. Please follow the instructions here\:
  https\:\/\/github.com\/jkulhanek\/tetra-nerf\/blob\/master\/README.md\#installation\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: tetra-nerf-original \'Tetra-NeRF. Official implementation from the paper\' tetra-nerf \'Tetra-NeRF. Different sampler - faster and better\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: None)]:_method.pip-package:"
)

_shtab_tyro_ns_train_tetra_nerf_original_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_tetra_nerf_original_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_tetra_nerf_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_tetra_nerf_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)

_shtab_tyro_ns_train_vanilla_nerf_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: vanilla-nerf)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.datamanager.train-num-rays-per-batch[Number of rays per batch to use per training iteration. (default\: 1024)]:pipeline.datamanager.train-num-rays-per-batch:"
  "--pipeline.datamanager.train-num-images-to-sample-from[Number of images to sample during training iteration. (default\: -1)]:pipeline.datamanager.train-num-images-to-sample-from:"
  "--pipeline.datamanager.train-num-times-to-repeat-images[When not training on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.train-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-num-rays-per-batch[Number of rays per batch to use per eval iteration. (default\: 1024)]:pipeline.datamanager.eval-num-rays-per-batch:"
  "--pipeline.datamanager.eval-num-images-to-sample-from[Number of images to sample during eval iteration. (default\: -1)]:pipeline.datamanager.eval-num-images-to-sample-from:"
  "--pipeline.datamanager.eval-num-times-to-repeat-images[When not evaluating on all images, number of iterations before picking new images. If -1, never pick new images. (default\: -1)]:pipeline.datamanager.eval-num-times-to-repeat-images:"
  "--pipeline.datamanager.eval-image-indices[Specifies the image indices to use during eval\; if None, uses all. (default\: 0)]:pipeline.datamanager.eval-image-indices:"
  "--pipeline.datamanager.camera-res-scale-factor[The scale factor for scaling spatial data such as images, mask, semantics along with relevant information about camera intrinsics (default\: 1.0)]:pipeline.datamanager.camera-res-scale-factor:"
  "--pipeline.datamanager.patch-size[Size of patch to sample from. If \>1, patch-based sampling will be used. (default\: 1)]:pipeline.datamanager.patch-size:"
  "--pipeline.datamanager.pixel-sampler.num-rays-per-batch[Number of rays to sample per batch. (default\: 4096)]:pipeline.datamanager.pixel-sampler.num-rays-per-batch:"
  "--pipeline.datamanager.pixel-sampler.keep-full-image[Whether or not to include a reference to the full image in returned batch. (default\: False)]:pipeline.datamanager.pixel-sampler.keep-full-image:(True False)"
  "--pipeline.datamanager.pixel-sampler.is-equirectangular[List of whether or not camera i is equirectangular. (default\: False)]:pipeline.datamanager.pixel-sampler.is-equirectangular:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--pipeline.model.num-coarse-samples[Number of samples in coarse field evaluation (default\: 64)]:pipeline.model.num-coarse-samples:"
  "--pipeline.model.num-importance-samples[Number of samples in fine field evaluation (default\: 128)]:pipeline.model.num-importance-samples:"
  "--pipeline.model.enable-temporal-distortion[Specifies whether or not to include ray warping based on time. (default\: False)]:pipeline.model.enable-temporal-distortion:(True False)"
  "--pipeline.model.temporal-distortion-params.kind[(default\: DNERF)]:pipeline.model.temporal-distortion-params.kind:(DNERF)"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--optimizers.fields.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.fields.optimizer.weight-decay:"
  "--optimizers.fields.scheduler[(default\: None)]:optimizers.fields.scheduler:(None)"
  "--optimizers.temporal-distortion.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.temporal-distortion.optimizer.lr:"
  "--optimizers.temporal-distortion.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.temporal-distortion.optimizer.eps:"
  "--optimizers.temporal-distortion.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.temporal-distortion.optimizer.max-norm:"
  "--optimizers.temporal-distortion.optimizer.weight-decay[The weight decay to use. (default\: 0)]:optimizers.temporal-distortion.optimizer.weight-decay:"
  "--optimizers.temporal-distortion.scheduler[(default\: None)]:optimizers.temporal-distortion.scheduler:(None)"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
)

_shtab_tyro_ns_train_vanilla_nerf_arkit_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ARKitScenes folder with densely extracted scenes. (default\: \'data\\ARKitScenes\\3dod\\Validation\\41069021\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_vanilla_nerf_blender_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\blender\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_vanilla_nerf_colmap_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--images-path[Path to images directory relative to the data path. (default\: images)]:pipeline.datamanager.dataparser.images-path:_files"
  "--masks-path[Path to masks directory. If not set, masks are not loaded. (default\: None)]:pipeline.datamanager.dataparser.masks-path:_files"
  "--depths-path[Path to depth maps directory. If not set, depths are not loaded. (default\: None)]:pipeline.datamanager.dataparser.depths-path:_files"
  "--colmap-path[Path to the colmap reconstruction directory relative to the data path. (default\: \'sparse\\0\')]:pipeline.datamanager.dataparser.colmap-path:_files"
  "--load-3D-points[Whether to load the 3D points from the colmap reconstruction. (default\: False)]:pipeline.datamanager.dataparser.load-3D-points:(True False)"
  "--max-2D-matches-per-3D-point[Maximum number of 2D matches per 3D point. If set to -1, all 2D matches are loaded. If set to 0, no 2D matches are loaded. (default\: -1)]:pipeline.datamanager.dataparser.max-2D-matches-per-3D-point:"
)

_shtab_tyro_ns_train_vanilla_nerf_dnerf_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\dnerf\\lego\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
)

_shtab_tyro_ns_train_vanilla_nerf_dycheck_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\iphone\\mochi-high-five\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 5.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--downscale-factor[How much to downscale images. (default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-box-bound[Boundary of scene box. (default\: 1.5)]:pipeline.datamanager.dataparser.scene-box-bound:"
)

_shtab_tyro_ns_train_vanilla_nerf_instant_ngp_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: \'data\\ours\\posterv2\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene-scale[How much to scale the scene. (default\: 0.3333)]:pipeline.datamanager.dataparser.scene-scale:"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
)

_shtab_tyro_ns_train_vanilla_nerf_minimal_parser_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[(default\: \'\\home\\nikhil\\nerfstudio-main\\tests\\data\\lego_test\\minimal_parser\')]:pipeline.datamanager.dataparser.data:_files"
)

_shtab_tyro_ns_train_vanilla_nerf_nerfosr_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\NeRF-OSR\\Data\')]:pipeline.datamanager.dataparser.data:_files"
  "--scene[Which scene to load (default\: stjacob)]:pipeline.datamanager.dataparser.scene:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--use-masks[Whether to use masks. (default\: False)]:pipeline.datamanager.dataparser.use-masks:(True False)"
  "--orientation-method[The method to use for orientation. (default\: vertical)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use for centering. (default\: focus)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_vanilla_nerf_nerfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory or explicit json file path specifying location of data. (default\: .)]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--downscale-factor[How much to downscale images. If not set, images are chosen such that the max dimension is \<1600px. (default\: None)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--eval-mode[

The method to use for splitting the dataset into train and eval. Fraction splits based on a percentage for train and the remaining for eval. Filename splits based on filenames containing train\/eval. Interval uses every nth frame for eval. All uses all the images for any split. (default\: fraction)]:pipeline.datamanager.dataparser.eval-mode:(filename all fraction interval)"
  "--train-split-fraction[The percentage of the dataset to use for training. Only used when eval_mode is train-split-fraction. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--eval-interval[The interval between frames to use for eval. Only used when eval_mode is eval-interval. (default\: 8)]:pipeline.datamanager.dataparser.eval-interval:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_vanilla_nerf_nuscenes_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Name of the scene. (default\: scene-0103)]:pipeline.datamanager.dataparser.data:_files"
  "--data-dir[Path to NuScenes dataset. (default\: \'\\mnt\\local\\NuScenes\')]:pipeline.datamanager.dataparser.data-dir:_files -/"
  "--version[Dataset version. (default\: v1.0-mini)]:pipeline.datamanager.dataparser.version:(v1.0-mini v1.0-trainval)"
  "--cameras[Which cameras to use. (default\: FRONT)]:pipeline.datamanager.dataparser.cameras:(FRONT_LEFT BACK_RIGHT BACK BACK_LEFT FRONT_RIGHT FRONT)"
  "--mask-dir[Path to masks of dynamic objects. (default\: None)]:pipeline.datamanager.dataparser.mask-dir:_files -/"
  "--train-split-fraction[The percent of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--verbose[Load dataset with verbose messaging (default\: False)]:pipeline.datamanager.dataparser.verbose:(True False)"
)

_shtab_tyro_ns_train_vanilla_nerf_phototourism_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\phototourism\\brandenburg-gate\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 3.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--alpha-color[alpha color of background (default\: white)]:pipeline.datamanager.dataparser.alpha-color:"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--orientation-method[The method to use for orientation. (default\: up)]:pipeline.datamanager.dataparser.orientation-method:(vertical pca none up)"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
)

_shtab_tyro_ns_train_vanilla_nerf_scannet_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Path to ScanNet folder with densely extracted scenes. (default\: \'data\\scannet\\scene0423_02\')]:pipeline.datamanager.dataparser.data:_files"
  "--scale-factor[How much to scale the camera origins by. (default\: 1.0)]:pipeline.datamanager.dataparser.scale-factor:"
  "--scene-scale[How much to scale the region of interest by. (default\: 1.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--center-method[The method to use to center the poses. (default\: poses)]:pipeline.datamanager.dataparser.center-method:(poses none focus)"
  "--auto-scale-poses[Whether to automatically scale the poses to fit in \+\/- 1 bounding box. (default\: True)]:pipeline.datamanager.dataparser.auto-scale-poses:(True False)"
  "--train-split-fraction[The fraction of images to use for training. The remaining images are for eval. (default\: 0.9)]:pipeline.datamanager.dataparser.train-split-fraction:"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
)

_shtab_tyro_ns_train_vanilla_nerf_sdfstudio_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\DTU\\scan65\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-mono-prior[whether or not to load monocular depth and normal (default\: False)]:pipeline.datamanager.dataparser.include-mono-prior:(True False)"
  "--depth-unit-scale-factor[Scales the depth values to meters. Default value is 0.001 for a millimeter to meter conversion. (default\: 0.001)]:pipeline.datamanager.dataparser.depth-unit-scale-factor:"
  "--include-foreground-mask[whether or not to load foreground mask (default\: False)]:pipeline.datamanager.dataparser.include-foreground-mask:(True False)"
  "--downscale-factor[(default\: 1)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
  "--skip-every-for-val-split[sub sampling validation images (default\: 1)]:pipeline.datamanager.dataparser.skip-every-for-val-split:"
  "--auto-orient[(default\: True)]:pipeline.datamanager.dataparser.auto-orient:(True False)"
)

_shtab_tyro_ns_train_vanilla_nerf_sitcoms3d_data_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--data[Directory specifying location of data. (default\: \'data\\sitcoms3d\\TBBT-big_living_room\')]:pipeline.datamanager.dataparser.data:_files"
  "--include-semantics[whether or not to include loading of semantics data (default\: True)]:pipeline.datamanager.dataparser.include-semantics:(True False)"
  "--downscale-factor[(default\: 4)]:pipeline.datamanager.dataparser.downscale-factor:"
  "--scene-scale[

Sets the bounding cube to have edge length of this size. The longest dimension of the Sitcoms3D axis-aligned bbox will be scaled to this value. (default\: 2.0)]:pipeline.datamanager.dataparser.scene-scale:"
)

_shtab_tyro_ns_train_volinga_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--output-dir[relative or absolute output directory to save all checkpoints and logging (default\: outputs)]:output-dir:_files -/"
  "--method-name[Method name. Required to set in python or via cli (default\: volinga)]:method-name:"
  "--experiment-name[Experiment name. If None, will automatically be set to dataset name (default\: None)]:experiment-name:"
  "--project-name[Project name. (default\: nerfstudio-project)]:project-name:"
  "--timestamp[Experiment timestamp. (default\: \'\{timestamp\}\')]:timestamp:"
  "--machine.seed[random seed initialization (default\: 42)]:machine.seed:"
  "--machine.num-devices[total number of devices (e.g., gpus) available for train\/eval (default\: 1)]:machine.num-devices:"
  "--machine.num-machines[total number of distributed machines available (for DDP) (default\: 1)]:machine.num-machines:"
  "--machine.machine-rank[current machine\'s rank (for DDP) (default\: 0)]:machine.machine-rank:"
  "--machine.dist-url[distributed connection point (for DDP) (default\: auto)]:machine.dist-url:"
  "--machine.device-type[device type to use for training (default\: cuda)]:machine.device-type:(cpu cuda mps)"
  "--logging.relative-log-dir[relative path to save all logged events (default\: .)]:logging.relative-log-dir:_files -/"
  "--logging.steps-per-log[number of steps between logging stats (default\: 10)]:logging.steps-per-log:"
  "--logging.max-buffer-size[maximum history size to keep for computing running averages of stats. e.g. if 20, averages will be computed over past 20 occurrences. (default\: 20)]:logging.max-buffer-size:"
  "--logging.local-writer.enable[if True enables local logging, else disables (default\: True)]:logging.local-writer.enable:(True False)"
  "--logging.local-writer.stats-to-track[specifies which stats will be logged\/printed to terminal (default\: ITER_TRAIN_TIME TRAIN_RAYS_PER_SEC CURR_TEST_PSNR VIS_RAYS_PER_SEC TEST_RAYS_PER_SEC ETA)]:logging.local-writer.stats-to-track:(TRAIN_RAYS_PER_SEC TEST_RAYS_PER_SEC ITER_TRAIN_TIME TOTAL_TRAIN_TIME VIS_RAYS_PER_SEC CURR_TEST_PSNR ETA)"
  "--logging.local-writer.max-log-size[maximum number of rows to print before wrapping. if 0, will print everything. (default\: 10)]:logging.local-writer.max-log-size:"
  "--logging.profiler[how to profile the code\;
\"basic\" - prints speed of all decorated functions at the end of a program.
\"pytorch\" - same as basic, but it also traces few training steps. (default\: basic)]:logging.profiler:(basic pytorch none)"
  "--viewer.relative-log-filename[Filename to use for the log file. (default\: viewer_log_filename.txt)]:viewer.relative-log-filename:_files"
  "--viewer.websocket-port[The websocket port to connect to. If None, find an available port. (default\: None)]:viewer.websocket-port:"
  "--viewer.websocket-port-default[The default websocket port to connect to if websocket_port is not specified (default\: 7007)]:viewer.websocket-port-default:"
  "--viewer.websocket-host[The host address to bind the websocket server to. (default\: 0.0.0.0)]:viewer.websocket-host:"
  "--viewer.num-rays-per-chunk[number of rays per chunk to render with viewer (default\: 32768)]:viewer.num-rays-per-chunk:"
  "--viewer.max-num-display-images[Maximum number of training images to display in the viewer, to avoid lag. This does not change which images are actually used in training\/evaluation. If -1, display all. (default\: 512)]:viewer.max-num-display-images:"
  "--viewer.quit-on-train-completion[Whether to kill the training job when it has completed. Note this will stop rendering in the viewer. (default\: False)]:viewer.quit-on-train-completion:(True False)"
  "--viewer.image-format[Image format viewer should use\; jpeg is lossy compression, while png is lossless. (default\: jpeg)]:viewer.image-format:(png jpeg)"
  "--viewer.jpeg-quality[Quality tradeoff to use for jpeg compression. (default\: 90)]:viewer.jpeg-quality:"
  "--viewer.make-share-url[Viewer beta feature\: print a shareable URL. \`vis\` must be set to viewer_beta\; this flag is otherwise ignored. (default\: False)]:viewer.make-share-url:(True False)"
  "--pipeline.datamanager.data[Source of data, may not be used by all models. (default\: None)]:pipeline.datamanager.data:_files"
  "--pipeline.datamanager.masks-on-gpu[Process masks on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.masks-on-gpu:(True False)"
  "--pipeline.datamanager.images-on-gpu[Process images on GPU for speed at the expense of memory, if True. (default\: False)]:pipeline.datamanager.images-on-gpu:(True False)"
  "--pipeline.model.enable-collider[Whether to create a scene collider to filter rays. (default\: True)]:pipeline.model.enable-collider:(True False)"
  "--pipeline.model.collider-params[parameters to instantiate scene collider with (default\: near_plane 2.0 far_plane 6.0)]:pipeline.model.collider-params:"
  "--pipeline.model.loss-coefficients.rgb-loss-coarse[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-coarse:"
  "--pipeline.model.loss-coefficients.rgb-loss-fine[(default\: 1.0)]:pipeline.model.loss-coefficients.rgb-loss-fine:"
  "--pipeline.model.eval-num-rays-per-chunk[specifies number of rays per chunk during eval (default\: 4096)]:pipeline.model.eval-num-rays-per-chunk:"
  "--pipeline.model.prompt[A prompt to be used in text to NeRF models (default\: None)]:pipeline.model.prompt:"
  "--optimizers.fields.optimizer.lr[The learning rate to use. (default\: 0.0005)]:optimizers.fields.optimizer.lr:"
  "--optimizers.fields.optimizer.eps[The epsilon value to use. (default\: 1e-08)]:optimizers.fields.optimizer.eps:"
  "--optimizers.fields.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:optimizers.fields.optimizer.max-norm:"
  "--vis[Which visualizer to use. (default\: wandb)]:vis:(viewer_beta viewer+comet viewer viewer+wandb comet viewer+tensorboard wandb tensorboard)"
  "--data[Alias for --pipeline.datamanager.data (default\: None)]:data:_files"
  "--prompt[Alias for --pipeline.model.prompt (default\: None)]:prompt:"
  "--relative-model-dir[Relative path to save all checkpoints. (default\: nerfstudio_models)]:relative-model-dir:_files -/"
  "--load-scheduler[Whether to load the scheduler state_dict to resume training, if it exists. (default\: True)]:load-scheduler:(True False)"
  "--steps-per-save[Number of steps between saves. (default\: 1000)]:steps-per-save:"
  "--steps-per-eval-batch[Number of steps between randomly sampled batches of rays. (default\: 500)]:steps-per-eval-batch:"
  "--steps-per-eval-image[Number of steps between single eval images. (default\: 500)]:steps-per-eval-image:"
  "--steps-per-eval-all-images[Number of steps between eval all images. (default\: 25000)]:steps-per-eval-all-images:"
  "--max-num-iterations[Maximum number of iterations to run. (default\: 1000000)]:max-num-iterations:"
  "--mixed-precision[Whether or not to use mixed precision for training. (default\: False)]:mixed-precision:(True False)"
  "--use-grad-scaler[Use gradient scaler even if the automatic mixed precision is disabled. (default\: False)]:use-grad-scaler:(True False)"
  "--save-only-latest-checkpoint[Whether to only save the latest checkpoint or all checkpoints. (default\: True)]:save-only-latest-checkpoint:(True False)"
  "--load-dir[Optionally specify a pre-trained model directory to load from. (default\: None)]:load-dir:_files -/"
  "--load-step[Optionally specify model step to load from\; if none, will find most recent model in load_dir. (default\: None)]:load-step:"
  "--load-config[Path to config YAML file. (default\: None)]:load-config:_files"
  "--load-checkpoint[Path to checkpoint file. (default\: None)]:load-checkpoint:_files"
  "--log-gradients[Optionally log gradients during training (default\: False)]:log-gradients:(True False)"
  "--gradient-accumulation-steps[Number of steps to accumulate gradients over. (default\: 1)]:gradient-accumulation-steps:"
  "--_method.instructions[Instructions for installing the method. This will be printed to the console when the user tries to use the method. (default\: \'\\\[bold yellow\]Volinga\\\[\/bold yellow\]
For more information visit\: https\:\/\/docs.nerf.studio\/en\/latest\/extensions\/unreal_engine.html

To enable Volinga, you must install it first by running\:
  \\\[grey\]pip install git\+https\:\/\/github.com\/Volinga\/volinga-model\\\[\/grey\]\')]:_method.instructions:"
  "--_method.configurations[List of configurations for the method. Each configuration is a tuple of (registered slug, description) as it will be printed in --help. (default\: volinga \'Real-time rendering model from Volinga. Directly exportable to NVOL format at https\:\/\/volinga.ai\/\')]:_method.configurations:"
  "--_method.pip-package[Specifies a pip package if the method can be installed by running \`pip install \<pip_package\>\`. (default\: git\+https\:\/\/github.com\/Volinga\/volinga-model)]:_method.pip-package:"
)

_shtab_tyro_ns_train_volinga_pipeline_datamanager_camera_optimizer_None_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
)

_shtab_tyro_ns_train_volinga_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options=(
  "(- : *)"{-h,--help}"[show this help message and exit]"
  "--pipeline.datamanager.camera-optimizer.mode[Pose optimization strategy to use. If enabled, we recommend SO3xR3. (default\: off)]:pipeline.datamanager.camera-optimizer.mode:(off SE3 SO3xR3)"
  "--pipeline.datamanager.camera-optimizer.position-noise-std[Noise to add to initial positions. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.position-noise-std:"
  "--pipeline.datamanager.camera-optimizer.orientation-noise-std[Noise to add to initial orientations. Useful for debugging. (default\: 0.0)]:pipeline.datamanager.camera-optimizer.orientation-noise-std:"
  "--pipeline.datamanager.camera-optimizer.optimizer.lr[The learning rate to use. (default\: 0.0006)]:pipeline.datamanager.camera-optimizer.optimizer.lr:"
  "--pipeline.datamanager.camera-optimizer.optimizer.eps[The epsilon value to use. (default\: 1e-15)]:pipeline.datamanager.camera-optimizer.optimizer.eps:"
  "--pipeline.datamanager.camera-optimizer.optimizer.max-norm[The max norm to use for gradient clipping. (default\: None)]:pipeline.datamanager.camera-optimizer.optimizer.max-norm:"
  "--pipeline.datamanager.camera-optimizer.optimizer.weight-decay[The weight decay to use. (default\: 0)]:pipeline.datamanager.camera-optimizer.optimizer.weight-decay:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup[Learning rate before warmup. (default\: 1e-08)]:pipeline.datamanager.camera-optimizer.scheduler.lr-pre-warmup:"
  "--pipeline.datamanager.camera-optimizer.scheduler.lr-final[Final learning rate. If not provided, it will be set to the optimizers learning rate. (default\: None)]:pipeline.datamanager.camera-optimizer.scheduler.lr-final:"
  "--pipeline.datamanager.camera-optimizer.scheduler.warmup-steps[Number of warmup steps. (default\: 0)]:pipeline.datamanager.camera-optimizer.scheduler.warmup-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.max-steps[The maximum number of steps. (default\: 10000)]:pipeline.datamanager.camera-optimizer.scheduler.max-steps:"
  "--pipeline.datamanager.camera-optimizer.scheduler.ramp[The ramp function to use during the warmup. (default\: cosine)]:pipeline.datamanager.camera-optimizer.scheduler.ramp:(cosine linear)"
)


_shtab_tyro_ns_train() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_options+=(': :_shtab_tyro_ns_train_commands' '*::: :->ns-train')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_options

  case $state in
    ns-train)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train-$line[1]:"
      case $line[1] in
        depth-nerfacto) _shtab_tyro_ns_train_depth_nerfacto ;;
        dnerf) _shtab_tyro_ns_train_dnerf ;;
        generfacto) _shtab_tyro_ns_train_generfacto ;;
        in2n) _shtab_tyro_ns_train_in2n ;;
        in2n-small) _shtab_tyro_ns_train_in2n_small ;;
        in2n-tiny) _shtab_tyro_ns_train_in2n_tiny ;;
        instant-ngp) _shtab_tyro_ns_train_instant_ngp ;;
        instant-ngp-bounded) _shtab_tyro_ns_train_instant_ngp_bounded ;;
        kplanes) _shtab_tyro_ns_train_kplanes ;;
        kplanes-dynamic) _shtab_tyro_ns_train_kplanes_dynamic ;;
        lerf) _shtab_tyro_ns_train_lerf ;;
        lerf-big) _shtab_tyro_ns_train_lerf_big ;;
        lerf-lite) _shtab_tyro_ns_train_lerf_lite ;;
        mipnerf) _shtab_tyro_ns_train_mipnerf ;;
        nerfacto) _shtab_tyro_ns_train_nerfacto ;;
        nerfacto-big) _shtab_tyro_ns_train_nerfacto_big ;;
        nerfacto-huge) _shtab_tyro_ns_train_nerfacto_huge ;;
        nerfplayer-nerfacto) _shtab_tyro_ns_train_nerfplayer_nerfacto ;;
        nerfplayer-ngp) _shtab_tyro_ns_train_nerfplayer_ngp ;;
        neus) _shtab_tyro_ns_train_neus ;;
        neus-facto) _shtab_tyro_ns_train_neus_facto ;;
        phototourism) _shtab_tyro_ns_train_phototourism ;;
        reconstruction) _shtab_tyro_ns_train_reconstruction ;;
        semantic-nerfw) _shtab_tyro_ns_train_semantic_nerfw ;;
        tensorf) _shtab_tyro_ns_train_tensorf ;;
        tetra-nerf) _shtab_tyro_ns_train_tetra_nerf ;;
        tetra-nerf-original) _shtab_tyro_ns_train_tetra_nerf_original ;;
        vanilla-nerf) _shtab_tyro_ns_train_vanilla_nerf ;;
        volinga) _shtab_tyro_ns_train_volinga ;;
      esac
  esac
}

_shtab_tyro_ns_train_depth_nerfacto() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_depth_nerfacto_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_depth_nerfacto_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_depth_nerfacto_options+=(': :_shtab_tyro_ns_train_depth_nerfacto_commands' '*::: :->depth-nerfacto')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_options

  case $state in
    depth-nerfacto)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_depth_nerfacto-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_depth_nerfacto_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_dnerf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_dnerf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_dnerf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_dnerf_options+=(': :_shtab_tyro_ns_train_dnerf_commands' '*::: :->dnerf')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_dnerf_options

  case $state in
    dnerf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_dnerf-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_dnerf_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_dnerf_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_dnerf_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_generfacto() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_generfacto_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_generfacto_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_generfacto_options+=(': :_shtab_tyro_ns_train_generfacto_commands' '*::: :->generfacto')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_generfacto_options

  case $state in
    generfacto)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_generfacto-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_generfacto_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_generfacto_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_in2n() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_in2n_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_in2n_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_in2n_options+=(': :_shtab_tyro_ns_train_in2n_commands' '*::: :->in2n')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_in2n_options

  case $state in
    in2n)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_in2n-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_in2n_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_in2n_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_in2n_small() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_in2n_small_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_in2n_small_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_in2n_small_options+=(': :_shtab_tyro_ns_train_in2n_small_commands' '*::: :->in2n-small')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_in2n_small_options

  case $state in
    in2n-small)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_in2n_small-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_in2n_small_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_in2n_small_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_in2n_tiny() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_in2n_tiny_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_in2n_tiny_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_in2n_tiny_options+=(': :_shtab_tyro_ns_train_in2n_tiny_commands' '*::: :->in2n-tiny')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_in2n_tiny_options

  case $state in
    in2n-tiny)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_in2n_tiny-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_in2n_tiny_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_in2n_tiny_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_instant_ngp() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_instant_ngp_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_instant_ngp_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_instant_ngp_options+=(': :_shtab_tyro_ns_train_instant_ngp_commands' '*::: :->instant-ngp')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_options

  case $state in
    instant-ngp)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_instant_ngp-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_instant_ngp_bounded() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_instant_ngp_bounded_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_instant_ngp_bounded_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_instant_ngp_bounded_options+=(': :_shtab_tyro_ns_train_instant_ngp_bounded_commands' '*::: :->instant-ngp-bounded')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_options

  case $state in
    instant-ngp-bounded)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_instant_ngp_bounded-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_instant_ngp_bounded_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_kplanes() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_kplanes_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_kplanes_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_kplanes_options+=(': :_shtab_tyro_ns_train_kplanes_commands' '*::: :->kplanes')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_kplanes_options

  case $state in
    kplanes)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_kplanes-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_kplanes_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_kplanes_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_kplanes_dynamic() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_kplanes_dynamic_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_kplanes_dynamic_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_kplanes_dynamic_options+=(': :_shtab_tyro_ns_train_kplanes_dynamic_commands' '*::: :->kplanes-dynamic')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_kplanes_dynamic_options

  case $state in
    kplanes-dynamic)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_kplanes_dynamic-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_kplanes_dynamic_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_kplanes_dynamic_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_lerf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_lerf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_lerf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_lerf_options+=(': :_shtab_tyro_ns_train_lerf_commands' '*::: :->lerf')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_lerf_options

  case $state in
    lerf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_lerf-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_lerf_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_lerf_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_lerf_big() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_lerf_big_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_lerf_big_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_lerf_big_options+=(': :_shtab_tyro_ns_train_lerf_big_commands' '*::: :->lerf-big')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_lerf_big_options

  case $state in
    lerf-big)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_lerf_big-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_lerf_big_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_lerf_big_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_lerf_lite() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_lerf_lite_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_lerf_lite_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_lerf_lite_options+=(': :_shtab_tyro_ns_train_lerf_lite_commands' '*::: :->lerf-lite')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_lerf_lite_options

  case $state in
    lerf-lite)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_lerf_lite-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_lerf_lite_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_lerf_lite_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_mipnerf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_mipnerf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_mipnerf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_mipnerf_options+=(': :_shtab_tyro_ns_train_mipnerf_commands' '*::: :->mipnerf')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_mipnerf_options

  case $state in
    mipnerf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_mipnerf-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_mipnerf_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_nerfacto() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_nerfacto_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_nerfacto_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_nerfacto_options+=(': :_shtab_tyro_ns_train_nerfacto_commands' '*::: :->nerfacto')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_nerfacto_options

  case $state in
    nerfacto)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_nerfacto-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_nerfacto_big() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_nerfacto_big_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_nerfacto_big_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_nerfacto_big_options+=(': :_shtab_tyro_ns_train_nerfacto_big_commands' '*::: :->nerfacto-big')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_options

  case $state in
    nerfacto-big)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_nerfacto_big-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_big_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_nerfacto_huge() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_nerfacto_huge_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_nerfacto_huge_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_nerfacto_huge_options+=(': :_shtab_tyro_ns_train_nerfacto_huge_commands' '*::: :->nerfacto-huge')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_options

  case $state in
    nerfacto-huge)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_nerfacto_huge-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_nerfacto_huge_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_nerfplayer_nerfacto() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_nerfplayer_nerfacto_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_nerfplayer_nerfacto_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_nerfplayer_nerfacto_options+=(': :_shtab_tyro_ns_train_nerfplayer_nerfacto_commands' '*::: :->nerfplayer-nerfacto')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_nerfplayer_nerfacto_options

  case $state in
    nerfplayer-nerfacto)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_nerfplayer_nerfacto-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_nerfplayer_nerfacto_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_nerfplayer_nerfacto_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_nerfplayer_ngp() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_nerfplayer_ngp_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_nerfplayer_ngp_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_nerfplayer_ngp_options+=(': :_shtab_tyro_ns_train_nerfplayer_ngp_commands' '*::: :->nerfplayer-ngp')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_nerfplayer_ngp_options

  case $state in
    nerfplayer-ngp)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_nerfplayer_ngp-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_nerfplayer_ngp_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_nerfplayer_ngp_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_neus() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_neus_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_neus_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_neus_options+=(': :_shtab_tyro_ns_train_neus_commands' '*::: :->neus')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_neus_options

  case $state in
    neus)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_neus-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_neus_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_neus_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_neus_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_neus_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_neus_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_neus_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_neus_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_neus_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_neus_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_neus_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_neus_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_neus_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_neus_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_neus_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_neus_facto() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_neus_facto_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_neus_facto_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_neus_facto_options+=(': :_shtab_tyro_ns_train_neus_facto_commands' '*::: :->neus-facto')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_neus_facto_options

  case $state in
    neus-facto)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_neus_facto-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_neus_facto_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_phototourism() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_phototourism_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_phototourism_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_phototourism_options+=(': :_shtab_tyro_ns_train_phototourism_commands' '*::: :->phototourism')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_phototourism_options

  case $state in
    phototourism)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_phototourism-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_phototourism_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_phototourism_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_phototourism_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_reconstruction() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_reconstruction_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_reconstruction_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_reconstruction_options+=(': :_shtab_tyro_ns_train_reconstruction_commands' '*::: :->reconstruction')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_reconstruction_options

  case $state in
    reconstruction)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_reconstruction-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_reconstruction_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_semantic_nerfw() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_semantic_nerfw_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_semantic_nerfw_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_semantic_nerfw_options+=(': :_shtab_tyro_ns_train_semantic_nerfw_commands' '*::: :->semantic-nerfw')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_options

  case $state in
    semantic-nerfw)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_semantic_nerfw-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_semantic_nerfw_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_tensorf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_tensorf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_tensorf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_tensorf_options+=(': :_shtab_tyro_ns_train_tensorf_commands' '*::: :->tensorf')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_tensorf_options

  case $state in
    tensorf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_tensorf-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_tensorf_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_tensorf_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_tensorf_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_tetra_nerf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_tetra_nerf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_tetra_nerf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_tetra_nerf_options+=(': :_shtab_tyro_ns_train_tetra_nerf_commands' '*::: :->tetra-nerf')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_tetra_nerf_options

  case $state in
    tetra-nerf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_tetra_nerf-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_tetra_nerf_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_tetra_nerf_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_tetra_nerf_original() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_tetra_nerf_original_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_tetra_nerf_original_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_tetra_nerf_original_options+=(': :_shtab_tyro_ns_train_tetra_nerf_original_commands' '*::: :->tetra-nerf-original')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_tetra_nerf_original_options

  case $state in
    tetra-nerf-original)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_tetra_nerf_original-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_tetra_nerf_original_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_tetra_nerf_original_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_vanilla_nerf() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_vanilla_nerf_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_vanilla_nerf_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_vanilla_nerf_options+=(': :_shtab_tyro_ns_train_vanilla_nerf_commands' '*::: :->vanilla-nerf')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_options

  case $state in
    vanilla-nerf)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_vanilla_nerf-$line[1]:"
      case $line[1] in
        arkit-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_arkit_data_options ;;
        blender-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_blender_data_options ;;
        colmap) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_colmap_options ;;
        dnerf-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_dnerf_data_options ;;
        dycheck-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_dycheck_data_options ;;
        instant-ngp-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_instant_ngp_data_options ;;
        minimal-parser) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_minimal_parser_options ;;
        nerfosr-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_nerfosr_data_options ;;
        nerfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_nerfstudio_data_options ;;
        nuscenes-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_nuscenes_data_options ;;
        phototourism-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_phototourism_data_options ;;
        scannet-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_scannet_data_options ;;
        sdfstudio-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_sdfstudio_data_options ;;
        sitcoms3d-data) _arguments -C -s $_shtab_tyro_ns_train_vanilla_nerf_sitcoms3d_data_options ;;
      esac
  esac
}

_shtab_tyro_ns_train_volinga() {
  local context state line curcontext="$curcontext" one_or_more='(-)*' remainder='(*)'

  if ((${_shtab_tyro_ns_train_volinga_options[(I)${(q)one_or_more}*]} + ${_shtab_tyro_ns_train_volinga_options[(I)${(q)remainder}*]} == 0)); then  # noqa: E501
    _shtab_tyro_ns_train_volinga_options+=(': :_shtab_tyro_ns_train_volinga_commands' '*::: :->volinga')
  fi
  _arguments -C -s $_shtab_tyro_ns_train_volinga_options

  case $state in
    volinga)
      words=($line[1] "${words[@]}")
      (( CURRENT += 1 ))
      curcontext="${curcontext%:*:*}:_shtab_tyro_ns_train_volinga-$line[1]:"
      case $line[1] in
        pipeline.datamanager.camera-optimizer:None) _arguments -C -s $_shtab_tyro_ns_train_volinga_pipeline_datamanager_camera_optimizer_None_options ;;
        pipeline.datamanager.camera-optimizer:camera-optimizer-config) _arguments -C -s $_shtab_tyro_ns_train_volinga_pipeline_datamanager_camera_optimizer_camera_optimizer_config_options ;;
      esac
  esac
}



typeset -A opt_args
_shtab_tyro_ns_train "$@"
